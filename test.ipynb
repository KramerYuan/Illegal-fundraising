{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from category_encoders import TargetEncoder \n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "年报特征提取完毕！\n"
     ]
    }
   ],
   "source": [
    "# 年报基本信息\n",
    "annual_report_info = pd.read_csv(\"./train/annual_report_info.csv\")\n",
    "\n",
    "# 年报基本信息进行去重操作\n",
    "annual_report_info = annual_report_info.drop_duplicates()\n",
    "\n",
    "# 年报信息提取出特征\n",
    "annual_report_feature = annual_report_info.id.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# 根据id进行分组计算FUNDAM资金数额的均值\n",
    "temp = annual_report_info[[\"id\", \"FUNDAM\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"FUNDAM\":\"id_FUNDAM_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "# 删除 成员人数 字段\n",
    "annual_report_info[\"MEMNUM\"].isnull().sum()\n",
    "\n",
    "# 删除 农民人数 字段\n",
    "annual_report_info[\"FARNUM\"].isnull().sum()\n",
    "\n",
    "# 删除 本年度新增成员人数 字段\n",
    "annual_report_info[\"ANNNEWMEMNUM\"].isnull().sum()\n",
    "\n",
    "# 删除 本年度退出成员人数 字段\n",
    "annual_report_info[\"ANNREDMEMNUM\"].isnull().sum()\n",
    "\n",
    "# 根据id进行分组计算EMPNUM从业人数的均值\n",
    "temp = annual_report_info[[\"id\", \"EMPNUM\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"EMPNUM\":\"id_EMPNUM_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "# 取值为1和2的进行分箱\n",
    "def binning_2(x):\n",
    "    if x>=1.5 and x<=2:\n",
    "        return 2.0\n",
    "    elif x<1.5 and x>=1:\n",
    "        return 1.0\n",
    "    \n",
    "# 根据id进行分组计算 EMPNUMSIGN:从业人数是否公示 的平均取值，再进行数据分箱\n",
    "temp = annual_report_info[[\"id\", \"EMPNUMSIGN\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"EMPNUMSIGN\":\"id_EMPNUMSIGN_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "annual_report_feature[\"id_EMPNUMSIGN_mean\"] = annual_report_feature[\"id_EMPNUMSIGN_mean\"].apply(binning_2)\n",
    "\n",
    "# 先对经营状态(BUSSTNAME)进行编码，然后根据id分组计算经营状态的均值，然后再进行分箱\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(list(annual_report_info[\"BUSSTNAME\"].astype(str).values))\n",
    "annual_report_info[\"BUSSTNAME\"] = le.transform(annual_report_info[\"BUSSTNAME\"].astype(str).values)\n",
    "\n",
    "# 分箱函数\n",
    "def Binning_4(x):\n",
    "    if x < 0.5:\n",
    "        return \n",
    "    elif x < 1.5:\n",
    "        return 1.0\n",
    "    elif x<2.5:\n",
    "        return 2.0\n",
    "    elif x<3.5:\n",
    "        return 3.0\n",
    "    else :\n",
    "        return 4.0\n",
    "\n",
    "temp = annual_report_info[[\"id\", \"BUSSTNAME\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"BUSSTNAME\":\"id_BUSSTNAME_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "annual_report_feature[\"id_BUSSTNAME_mean\"] = annual_report_feature[\"id_BUSSTNAME_mean\"].apply(Binning_4)\n",
    "\n",
    "# 根据id进行分组计算 COLGRANUM:其中高校毕业生人数经营者 的均值\n",
    "temp = annual_report_info[[\"id\", \"COLGRANUM\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"COLGRANUM\":\"id_COLGRANUM_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "# 根据id进行分组计算 RETSOLNUM:其中退役士兵人数经营者 的均值\n",
    "temp = annual_report_info[[\"id\", \"RETSOLNUM\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"RETSOLNUM\":\"id_RETSOLNUM_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "# 根据id进行分组计算 DISPERNUM:其中残疾人人数经营者 的均值\n",
    "temp = annual_report_info[[\"id\", \"DISPERNUM\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"DISPERNUM\":\"id_DISPERNUM_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "# 根据id进行分组计算 UNENUM:其中下岗失业人数经营者 的均值\n",
    "temp = annual_report_info[[\"id\", \"UNENUM\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"UNENUM\":\"id_UNENUM_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "# 根据id进行分组计算 COLEMPLNUM:其中高校毕业生人数雇员 的均值\n",
    "temp = annual_report_info[[\"id\", \"COLEMPLNUM\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"COLEMPLNUM\":\"id_COLEMPLNUM_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "# 根据id进行分组计算 RETEMPLNUM:其中退役士兵人数雇员 的均值\n",
    "temp = annual_report_info[[\"id\", \"RETEMPLNUM\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"RETEMPLNUM\":\"id_RETEMPLNUM_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "# 根据id进行分组计算 DISEMPLNUM:其中残疾人人数雇员 的均值\n",
    "temp = annual_report_info[[\"id\", \"DISEMPLNUM\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"DISEMPLNUM\":\"id_DISEMPLNUM_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "# 根据id进行分组计算 UNEEMPLNUM:其中下岗失业人数雇员 的均值\n",
    "temp = annual_report_info[[\"id\", \"UNEEMPLNUM\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"UNEEMPLNUM\":\"id_UNEEMPLNUM_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "# 根据id进行分组计算 WEBSITSIGN:是否有网站标志 的均值  再分箱\n",
    "temp = annual_report_info[[\"id\", \"WEBSITSIGN\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"WEBSITSIGN\":\"id_WEBSITSIGN_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "annual_report_feature[\"id_WEBSITSIGN_mean\"] = annual_report_feature[\"id_WEBSITSIGN_mean\"].apply(binning_2)\n",
    "\n",
    "# 根据id进行分组计算 FORINVESTSIGN:是否有对外投资企业标志 的均值    再分箱\n",
    "temp = annual_report_info[[\"id\", \"FORINVESTSIGN\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"FORINVESTSIGN\":\"id_FORINVESTSIGN_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "annual_report_feature[\"id_FORINVESTSIGN_mean\"] = annual_report_feature[\"id_FORINVESTSIGN_mean\"].apply(binning_2)\n",
    "\n",
    "# 根据id进行分组计算 STOCKTRANSIGN:有限责任公司本年度是否发生股东股权转让标志 的均值  再分箱\n",
    "temp = annual_report_info[[\"id\", \"STOCKTRANSIGN\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"STOCKTRANSIGN\":\"id_STOCKTRANSIGN_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "annual_report_feature[\"id_STOCKTRANSIGN_mean\"] = annual_report_feature[\"id_STOCKTRANSIGN_mean\"].apply(binning_2)\n",
    "\n",
    "def binning_3(x):\n",
    "    if x>=1 and x<1.5:\n",
    "        return 1.0\n",
    "    elif x>=1.5 and x<2.5:\n",
    "        return 2.0\n",
    "    elif x>=2.5 and x<=3:\n",
    "        return 3.0\n",
    "    \n",
    "# 根据id进行分组计算 PUBSTATE:公示状态 的均值  再分箱\n",
    "temp = annual_report_info[[\"id\", \"PUBSTATE\"]].groupby(\"id\").mean()\n",
    "\n",
    "temp = temp.rename(columns={\"PUBSTATE\":\"id_PUBSTATE_mean\"})\n",
    "\n",
    "annual_report_feature = pd.merge(annual_report_feature,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "annual_report_feature[\"id_STOCKTRANSIGN_mean\"] = annual_report_feature[\"id_STOCKTRANSIGN_mean\"].apply(binning_3)\n",
    "\n",
    "print(\"年报特征提取完毕！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_FUNDAM_mean</th>\n",
       "      <th>id_EMPNUM_mean</th>\n",
       "      <th>id_EMPNUMSIGN_mean</th>\n",
       "      <th>id_BUSSTNAME_mean</th>\n",
       "      <th>id_COLGRANUM_mean</th>\n",
       "      <th>id_RETSOLNUM_mean</th>\n",
       "      <th>id_DISPERNUM_mean</th>\n",
       "      <th>id_UNENUM_mean</th>\n",
       "      <th>id_COLEMPLNUM_mean</th>\n",
       "      <th>id_RETEMPLNUM_mean</th>\n",
       "      <th>id_DISEMPLNUM_mean</th>\n",
       "      <th>id_UNEEMPLNUM_mean</th>\n",
       "      <th>id_WEBSITSIGN_mean</th>\n",
       "      <th>id_FORINVESTSIGN_mean</th>\n",
       "      <th>id_STOCKTRANSIGN_mean</th>\n",
       "      <th>id_PUBSTATE_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9c7fa510616a683058ce97d0bc768a621cd85ab1e87da2a3</td>\n",
       "      <td>3.50</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f000950527a6feb63ee1ce82bb22ddd1ab8b8fdffa3b91fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9c7fa510616a68309e4badf2a7a3123c0462fb85bf28ef17</td>\n",
       "      <td>13.50</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>755db3b5c5f74eb48564a8be9d4a9d7038ed96bc2eea645c</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e9f7b28ec10e0470287f274dd5a327519e74d2eb9506faad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8932</th>\n",
       "      <td>59b38c56de38368333bc0aea6c88cd7dae33b1c5cf9e5cc5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8933</th>\n",
       "      <td>f000950527a6feb6de489447885cd6d18f593ec2674174ac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>f1c1045b13d18329a2bd99d2a7e2227688c0d69bf1d1e325</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8935</th>\n",
       "      <td>f000950527a6feb6bde38216d7cbbf32e66d3a3a96d4dbda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8936</th>\n",
       "      <td>516ab81418ed215dcbbf0614a7b929e691f8eed153d7bb31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8937 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id  id_FUNDAM_mean  \\\n",
       "0     9c7fa510616a683058ce97d0bc768a621cd85ab1e87da2a3            3.50   \n",
       "1     f000950527a6feb63ee1ce82bb22ddd1ab8b8fdffa3b91fb             NaN   \n",
       "2     9c7fa510616a68309e4badf2a7a3123c0462fb85bf28ef17           13.50   \n",
       "3     755db3b5c5f74eb48564a8be9d4a9d7038ed96bc2eea645c            2.00   \n",
       "4     e9f7b28ec10e0470287f274dd5a327519e74d2eb9506faad             NaN   \n",
       "...                                                ...             ...   \n",
       "8932  59b38c56de38368333bc0aea6c88cd7dae33b1c5cf9e5cc5             NaN   \n",
       "8933  f000950527a6feb6de489447885cd6d18f593ec2674174ac             NaN   \n",
       "8934  f1c1045b13d18329a2bd99d2a7e2227688c0d69bf1d1e325            4.25   \n",
       "8935  f000950527a6feb6bde38216d7cbbf32e66d3a3a96d4dbda             NaN   \n",
       "8936  516ab81418ed215dcbbf0614a7b929e691f8eed153d7bb31             NaN   \n",
       "\n",
       "      id_EMPNUM_mean  id_EMPNUMSIGN_mean  id_BUSSTNAME_mean  \\\n",
       "0           6.000000                 NaN                NaN   \n",
       "1           3.500000                 2.0                2.0   \n",
       "2          16.000000                 NaN                NaN   \n",
       "3           1.000000                 NaN                NaN   \n",
       "4           5.666667                 2.0                2.0   \n",
       "...              ...                 ...                ...   \n",
       "8932        1.000000                 2.0                3.0   \n",
       "8933        4.750000                 2.0                2.0   \n",
       "8934        2.250000                 NaN                NaN   \n",
       "8935        2.250000                 2.0                2.0   \n",
       "8936        5.000000                 2.0                3.0   \n",
       "\n",
       "      id_COLGRANUM_mean  id_RETSOLNUM_mean  id_DISPERNUM_mean  id_UNENUM_mean  \\\n",
       "0                  0.00                0.0                0.0            0.00   \n",
       "1                  2.00                0.0                0.0            0.00   \n",
       "2                  0.00                0.0                0.0            0.00   \n",
       "3                  0.00                0.0                0.0            0.00   \n",
       "4                   NaN                NaN                NaN             NaN   \n",
       "...                 ...                ...                ...             ...   \n",
       "8932               0.00                0.0                0.0            0.00   \n",
       "8933               2.00                0.0                0.0            1.00   \n",
       "8934               0.00                0.0                0.0            0.00   \n",
       "8935               0.75                0.0                0.0            0.25   \n",
       "8936               0.00                0.0                0.0            0.00   \n",
       "\n",
       "      id_COLEMPLNUM_mean  id_RETEMPLNUM_mean  id_DISEMPLNUM_mean  \\\n",
       "0                   0.00                0.00                 0.0   \n",
       "1                   1.50                0.00                 0.0   \n",
       "2                   0.00                0.00                 0.0   \n",
       "3                   0.00                0.00                 0.0   \n",
       "4                    NaN                 NaN                 NaN   \n",
       "...                  ...                 ...                 ...   \n",
       "8932                0.00                0.00                 0.0   \n",
       "8933                2.50                0.00                 0.0   \n",
       "8934                0.00                0.00                 0.0   \n",
       "8935                0.75                0.25                 0.0   \n",
       "8936                0.00                0.00                 0.0   \n",
       "\n",
       "      id_UNEEMPLNUM_mean  id_WEBSITSIGN_mean  id_FORINVESTSIGN_mean  \\\n",
       "0                   0.00                 2.0                    NaN   \n",
       "1                   0.00                 2.0                    2.0   \n",
       "2                   0.00                 2.0                    NaN   \n",
       "3                   0.00                 2.0                    NaN   \n",
       "4                    NaN                 2.0                    2.0   \n",
       "...                  ...                 ...                    ...   \n",
       "8932                0.00                 2.0                    2.0   \n",
       "8933                1.50                 2.0                    2.0   \n",
       "8934                0.00                 2.0                    NaN   \n",
       "8935                0.25                 2.0                    2.0   \n",
       "8936                0.00                 2.0                    2.0   \n",
       "\n",
       "      id_STOCKTRANSIGN_mean  id_PUBSTATE_mean  \n",
       "0                       NaN              3.00  \n",
       "1                       2.0              3.00  \n",
       "2                       NaN              3.00  \n",
       "3                       NaN              3.00  \n",
       "4                       2.0              3.00  \n",
       "...                     ...               ...  \n",
       "8932                    NaN              3.00  \n",
       "8933                    2.0              2.75  \n",
       "8934                    NaN              3.00  \n",
       "8935                    NaN              2.25  \n",
       "8936                    2.0              3.00  \n",
       "\n",
       "[8937 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annual_report_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "纳税特征提取完成！\n"
     ]
    }
   ],
   "source": [
    "# 读取纳税信息\n",
    "tax_info = pd.read_csv(\"./train/tax_info.csv\")\n",
    "\n",
    "# 去除（29195 - 24614）条重复数据\n",
    "tax_info = tax_info.drop_duplicates()\n",
    "\n",
    "# 提取tax表格中的id\n",
    "tax_feature = tax_info.id.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# 将提取出来的id转换成dataframe\n",
    "tax_feature = pd.DataFrame(tax_feature)\n",
    "\n",
    "# 将有id的部分赋值为1\n",
    "tax_feature[\"is_tax_exist\"] = 1\n",
    "\n",
    "# # 连接上其余特征\n",
    "# data = pd.merge(data, tax_feature, on=\"id\", how=\"left\")\n",
    "# # 将没有tax信息的id填充为0\n",
    "# data[\"is_tax_exist\"].fillna(0,inplace=True)\n",
    "\n",
    "print(\"纳税特征提取完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_tax_exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f000950527a6feb6c2f40c9d8477e73a439dfa0897830397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d8071a739aa75a3b9f23966f8dae78fd226c272515b9c255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d8071a739aa75a3b8beaa7f2ea3a364a1bf8faefec72f871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f000950527a6feb6207093f8cac7a11cc2abd1763a264757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f000950527a6feb6f97af739bb95531db891a11df80bdb8b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>47645761dc56bb8cf147c0f51d60cfe28fd995aaca7693d9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>f000950527a6feb6bd25a1d6ac6f6463fa2d6e21e0d2861b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>d8071a739aa75a3b6860158ec0cc8ba7972fb14ba37b9e0a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>f000950527a6feb6cb8976eb56233ede461cb23103f85f32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>d8071a739aa75a3bbb9e08ebd134ae1289f194b70cac0e95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>808 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   id  is_tax_exist\n",
       "0    f000950527a6feb6c2f40c9d8477e73a439dfa0897830397             1\n",
       "1    d8071a739aa75a3b9f23966f8dae78fd226c272515b9c255             1\n",
       "2    d8071a739aa75a3b8beaa7f2ea3a364a1bf8faefec72f871             1\n",
       "3    f000950527a6feb6207093f8cac7a11cc2abd1763a264757             1\n",
       "4    f000950527a6feb6f97af739bb95531db891a11df80bdb8b             1\n",
       "..                                                ...           ...\n",
       "803  47645761dc56bb8cf147c0f51d60cfe28fd995aaca7693d9             1\n",
       "804  f000950527a6feb6bd25a1d6ac6f6463fa2d6e21e0d2861b             1\n",
       "805  d8071a739aa75a3b6860158ec0cc8ba7972fb14ba37b9e0a             1\n",
       "806  f000950527a6feb6cb8976eb56233ede461cb23103f85f32             1\n",
       "807  d8071a739aa75a3bbb9e08ebd134ae1289f194b70cac0e95             1\n",
       "\n",
       "[808 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tax_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "变更信息提取完成！\n"
     ]
    }
   ],
   "source": [
    "# 读取变更信息\n",
    "change_info = pd.read_csv(\"./train/change_info.csv\")\n",
    "\n",
    "# 45940 - 45216 去重\n",
    "change_info = change_info.drop_duplicates()\n",
    "\n",
    "# 添加一列计数\n",
    "change_info[\"cnt\"] = 1\n",
    "\n",
    "# 提取变更信息的次数\n",
    "temp = change_info[[\"id\", \"cnt\"]].groupby(\"id\").count()\n",
    "\n",
    "temp = temp.rename(columns={\"cnt\":\"count_change\"})\n",
    "\n",
    "def change_fea(x):\n",
    "    if x>5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# 对变更信息计数特征进行分箱\n",
    "temp[\"count_change\"] = temp[\"count_change\"].apply(change_fea)\n",
    "\n",
    "change_fea = change_info.id.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "change_fea = pd.merge(change_fea,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "print(\"变更信息提取完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>count_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9c7fa510616a683058ce97d0bc768a621cd85ab1e87da2a3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e9f7b28ec10e047000d16ab79e1b5e6da434a1697cce7818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f000950527a6feb63ee1ce82bb22ddd1ab8b8fdffa3b91fb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>216bd2aaf4d07924b4a106be25791281e2a6d9e54eaee13b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>743e550a617316d5772a00182284976e17d42b6f0ca6d374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8721</th>\n",
       "      <td>d8071a739aa75a3b2cf30bec1c008a658963648897cb375b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8722</th>\n",
       "      <td>f000950527a6feb6de489447885cd6d18f593ec2674174ac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8723</th>\n",
       "      <td>f1c1045b13d18329a2bd99d2a7e2227688c0d69bf1d1e325</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8724</th>\n",
       "      <td>da8691b210adb3f65b43370d3a362f4aa1d3b16b5ba0c9d7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8725</th>\n",
       "      <td>9c7fa510616a68303d3427d4bfd4b0cf3e4843f2bf3f637a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id  count_change\n",
       "0     9c7fa510616a683058ce97d0bc768a621cd85ab1e87da2a3             1\n",
       "1     e9f7b28ec10e047000d16ab79e1b5e6da434a1697cce7818             1\n",
       "2     f000950527a6feb63ee1ce82bb22ddd1ab8b8fdffa3b91fb             1\n",
       "3     216bd2aaf4d07924b4a106be25791281e2a6d9e54eaee13b             1\n",
       "4     743e550a617316d5772a00182284976e17d42b6f0ca6d374             1\n",
       "...                                                ...           ...\n",
       "8721  d8071a739aa75a3b2cf30bec1c008a658963648897cb375b             1\n",
       "8722  f000950527a6feb6de489447885cd6d18f593ec2674174ac             1\n",
       "8723  f1c1045b13d18329a2bd99d2a7e2227688c0d69bf1d1e325             2\n",
       "8724  da8691b210adb3f65b43370d3a362f4aa1d3b16b5ba0c9d7             1\n",
       "8725  9c7fa510616a68303d3427d4bfd4b0cf3e4843f2bf3f637a             1\n",
       "\n",
       "[8726 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新闻特征提取完成！\n"
     ]
    }
   ],
   "source": [
    "# 读取新闻信息\n",
    "news_info = pd.read_csv(\"./train/news_info.csv\")\n",
    "\n",
    "# 对新闻进行特征进行映射编码\n",
    "def encode(x):\n",
    "    if x==\"积极\":\n",
    "        return 1\n",
    "    if x==\"中立\":\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "news_info[\"positive_negtive\"] = news_info[\"positive_negtive\"].apply(encode)\n",
    "\n",
    "# 统计不同信息的\n",
    "temp = news_info[[\"id\", \"positive_negtive\"]].groupby(\"id\").sum()\n",
    "\n",
    "temp = temp.rename(columns={\"positive_negtive\":\"news_count\"})\n",
    "\n",
    "# 进行分箱\n",
    "def news_fea(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    elif x<0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 对计数特征进行分箱\n",
    "temp[\"news_count\"] = temp[\"news_count\"].apply(news_fea)\n",
    "\n",
    "# 提取新闻数据id\n",
    "news_fea = news_info.id.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "news_fea = pd.merge(news_fea,temp,how=\"left\",on=\"id\")\n",
    "\n",
    "print(\"新闻特征提取完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>news_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f000950527a6feb62669d6a175fe6fdccd1eb4f7ca8e5016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f000950527a6feb6e8bd9919e2ca363359bcfa997a0f9de7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d8071a739aa75a3bcf6fb0041ee883243251d30025ab9d45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f000950527a6feb6d71de3382afa0bc5ff87bb65477f698a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f000950527a6feb65929509d9be855bf75b7337d4465843e</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>d8071a739aa75a3be6f3e200fd5532cb96764b8f4623c75a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>f000950527a6feb69ea351e48351a711fb09bf1b83f04dfc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>e9f7b28ec10e047005eec1a07b716d63fac8742cbdeacd46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>d8071a739aa75a3b6860158ec0cc8ba7972fb14ba37b9e0a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>f000950527a6feb6de489447885cd6d18f593ec2674174ac</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>927 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   id  news_count\n",
       "0    f000950527a6feb62669d6a175fe6fdccd1eb4f7ca8e5016           1\n",
       "1    f000950527a6feb6e8bd9919e2ca363359bcfa997a0f9de7          -1\n",
       "2    d8071a739aa75a3bcf6fb0041ee883243251d30025ab9d45           0\n",
       "3    f000950527a6feb6d71de3382afa0bc5ff87bb65477f698a           1\n",
       "4    f000950527a6feb65929509d9be855bf75b7337d4465843e           1\n",
       "..                                                ...         ...\n",
       "922  d8071a739aa75a3be6f3e200fd5532cb96764b8f4623c75a           0\n",
       "923  f000950527a6feb69ea351e48351a711fb09bf1b83f04dfc           0\n",
       "924  e9f7b28ec10e047005eec1a07b716d63fac8742cbdeacd46           0\n",
       "925  d8071a739aa75a3b6860158ec0cc8ba7972fb14ba37b9e0a           1\n",
       "926  f000950527a6feb6de489447885cd6d18f593ec2674174ac          -1\n",
       "\n",
       "[927 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其他信息提取完成！\n"
     ]
    }
   ],
   "source": [
    "# 其他消息的读取\n",
    "other_info = pd.read_csv(\"./train/other_info.csv\")\n",
    "\n",
    "# 删除4条错误数据\n",
    "other_info = other_info.drop(index=(other_info.loc[(other_info[\"id\"] == \"f000950527a6feb63702b1f6c1dabe5ea196d320bbbff425\")].index))\n",
    "\n",
    "other_info = other_info.drop(index=(other_info.loc[(other_info[\"id\"] == \"e9f7b28ec10e04707ba878b89e6c2d362b107a817342f9c6\")].index))\n",
    "\n",
    "other_fea = other_info\n",
    "\n",
    "print(\"其他信息提取完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>legal_judgment_num</th>\n",
       "      <th>brand_num</th>\n",
       "      <th>patent_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f000950527a6feb6d340f91da09e61347d8200cd2f0d1602</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f000950527a6feb608dd9322b74a99f60851207f36a3c94c</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d8071a739aa75a3b9f23966f8dae78fd226c272515b9c255</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>216bd2aaf4d079242209b1496f81a36c7abed9dd0bb65ed3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e9f7b28ec10e0470de9631c789f49acdd4e7cf9ed6db094b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>47645761dc56bb8cf147c0f51d60cfe28fd995aaca7693d9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>f000950527a6feb69ea351e48351a711fb09bf1b83f04dfc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>d8071a739aa75a3b39130af3718b2f261b57833a6a58ba55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>d8071a739aa75a3b6860158ec0cc8ba7972fb14ba37b9e0a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>f000950527a6feb6de489447885cd6d18f593ec2674174ac</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1886 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id  legal_judgment_num  \\\n",
       "0     f000950527a6feb6d340f91da09e61347d8200cd2f0d1602                 4.0   \n",
       "1     f000950527a6feb608dd9322b74a99f60851207f36a3c94c                 1.0   \n",
       "2     d8071a739aa75a3b9f23966f8dae78fd226c272515b9c255                 2.0   \n",
       "3     216bd2aaf4d079242209b1496f81a36c7abed9dd0bb65ed3                 NaN   \n",
       "4     e9f7b28ec10e0470de9631c789f49acdd4e7cf9ed6db094b                 NaN   \n",
       "...                                                ...                 ...   \n",
       "1885  47645761dc56bb8cf147c0f51d60cfe28fd995aaca7693d9                 6.0   \n",
       "1886  f000950527a6feb69ea351e48351a711fb09bf1b83f04dfc                 1.0   \n",
       "1887  d8071a739aa75a3b39130af3718b2f261b57833a6a58ba55                 2.0   \n",
       "1888  d8071a739aa75a3b6860158ec0cc8ba7972fb14ba37b9e0a                 1.0   \n",
       "1889  f000950527a6feb6de489447885cd6d18f593ec2674174ac                40.0   \n",
       "\n",
       "      brand_num  patent_num  \n",
       "0           NaN         NaN  \n",
       "1           NaN         NaN  \n",
       "2           NaN         NaN  \n",
       "3           1.0         NaN  \n",
       "4           2.0         NaN  \n",
       "...         ...         ...  \n",
       "1885        NaN         NaN  \n",
       "1886        NaN         NaN  \n",
       "1887        1.0         NaN  \n",
       "1888        NaN         NaN  \n",
       "1889        NaN         NaN  \n",
       "\n",
       "[1886 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本信息\n",
    "base_info = pd.read_csv(\"./train/base_info.csv\")\n",
    "\n",
    "# id + 标签\n",
    "entprise_info = pd.read_csv(\"./train/entprise_info.csv\")\n",
    "\n",
    "# id + 标签(Null) \n",
    "result = pd.read_csv(\"./entprise_evaluate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([entprise_info,result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将base_info和label进行连接，label为空的是测试集\n",
    "data = pd.merge(temp, base_info, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连接变更信息特征\n",
    "data = pd.merge(data, change_fea, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连接税务特征\n",
    "data = pd.merge(data, tax_feature, on=\"id\", how=\"left\")\n",
    "# 空值用0填充\n",
    "data[\"is_tax_exist\"].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连接新闻特征\n",
    "data = pd.merge(data, news_fea, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连接其他特征\n",
    "data = pd.merge(data, other_fea, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连接年报特征\n",
    "data = pd.merge(data, annual_report_feature, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['opfrom'] = pd.to_datetime(data['opfrom'],format='%Y-%m-%d')\n",
    "data['opto'] = pd.to_datetime(data['opto'],format='%Y-%m-%d')\n",
    "# 构造时间特征\n",
    "data[\"time\"] = (data[\"opto\"] - data[\"opfrom\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用目标编码对industryphy列进行训练 \n",
    "enc = TargetEncoder()  \n",
    "data[\"industryphy\"] = enc.fit_transform(data[\"industryphy\"], data[\"label\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用目标编码对opform列进行训练 \n",
    "enc = TargetEncoder()  \n",
    "data[\"opform\"] = enc.fit_transform(data[\"opform\"], data[\"label\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用目标编码对opform列进行训练\n",
    "enc = TargetEncoder()  \n",
    "data[\"oploc\"] = enc.fit_transform(data[\"oploc\"], data[\"label\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.label.notnull()].reset_index(drop=True)\n",
    "test = data[data.label.isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop([\"id\", \"dom\", \"opscope\", \"opfrom\", \"opto\", \"label\", \"score\"], axis=1)\n",
    "test = test.drop([\"id\", \"dom\", \"opscope\", \"opfrom\", \"opto\", \"label\", \"score\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name):\n",
    "    folds = 5\n",
    "    seed = 1024\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test_pred = np.zeros(test_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "    importance = np.zeros(train_x.columns.shape[0])\n",
    "    \n",
    "    cv_scores = []\n",
    "    feature_names = train_x.columns.tolist()\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y)\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'min_child_weight': 5,\n",
    "                'num_leaves': 2 ** 5,\n",
    "                'lambda_l2': 10,\n",
    "                'tree_method':'gpu_hist',\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 4,\n",
    "                'learning_rate': 0.05,\n",
    "                'seed': 1024,\n",
    "                'nthread': 28,\n",
    "                'n_jobs':24,\n",
    "                'silent': True,\n",
    "                'verbose': -1,\n",
    "            }\n",
    "\n",
    "            model = clf.train(params, train_matrix, 50000, valid_sets=[train_matrix, valid_matrix], verbose_eval=200,early_stopping_rounds=200)\n",
    "            \n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration)\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
    "            \n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y)\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y)\n",
    "            test_matrix = clf.DMatrix(test_x)\n",
    "            \n",
    "            params = {'booster': 'gbtree',\n",
    "                      'objective': 'binary:logistic',\n",
    "                      'eval_metric': 'auc',\n",
    "                      'gamma': 1,\n",
    "                      'min_child_weight': 1.5,\n",
    "                      'max_depth': 5,\n",
    "                      'lambda': 10,\n",
    "                      'subsample': 0.7,\n",
    "                      'tree_method':'gpu_hist',\n",
    "                      'colsample_bytree': 0.7,\n",
    "                      'colsample_bylevel': 0.7,\n",
    "                      'eta': 0.04,\n",
    "                      'tree_method': 'exact',\n",
    "                      'seed': 1024,\n",
    "                      'nthread': 36,\n",
    "                      \"silent\": True,\n",
    "                      }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            \n",
    "            model = clf.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=200, early_stopping_rounds=200)\n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit)\n",
    "            test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit)\n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            params = {'learning_rate': 0.05, 'depth': 5, 'l2_leaf_reg': 10, 'bootstrap_type': 'Bernoulli',\n",
    "                      'od_type': 'Iter', 'od_wait': 50, 'random_seed': 11, 'allow_writing_files': False}\n",
    "            \n",
    "            model = clf(iterations=20000, **params)\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      cat_features=[], use_best_model=True, verbose=500)\n",
    "            \n",
    "            val_pred  = model.predict(val_x)\n",
    "            test_pred = model.predict(test_x)\n",
    "            \n",
    "            \n",
    "        # importance += model.feature_importance() / 5\n",
    "        \n",
    "        train[valid_index] = val_pred\n",
    "        test += test_pred / kf.n_splits\n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        \n",
    "        print(cv_scores)\n",
    "    \n",
    "    # df = pd.DataFrame({ 'column': feature_names, 'importance': importance}).sort_values(by='importance')           \n",
    "    # df.to_csv(\"./importance.csv\")\n",
    "    print(\"%s_scotrainre_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return test\n",
    "\n",
    "def lgb_model(x_train, y_train, x_test):\n",
    "    lgb_test = cv_model(lgb, x_train, y_train, x_test, \"lgb\")\n",
    "    return lgb_test\n",
    "\n",
    "def xgb_model(x_train, y_train, x_test):\n",
    "    xgb_test = cv_model(xgb, x_train, y_train, x_test, \"xgb\")\n",
    "    return xgb_test\n",
    "\n",
    "def cat_model(x_train, y_train, x_test):\n",
    "    cat_test = cv_model(CatBoostRegressor, x_train, y_train, x_test, \"cat\")\n",
    "    return cat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "[21:45:43] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.98397\teval-auc:0.97425\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.99567\teval-auc:0.99137\n",
      "[400]\ttrain-auc:0.99733\teval-auc:0.99169\n",
      "Stopping. Best iteration:\n",
      "[347]\ttrain-auc:0.99701\teval-auc:0.99179\n",
      "\n",
      "[0.9917938387500198]\n",
      "************************************ 2 ************************************\n",
      "[21:45:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.98126\teval-auc:0.97440\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.99635\teval-auc:0.98767\n",
      "[400]\ttrain-auc:0.99779\teval-auc:0.98822\n",
      "Stopping. Best iteration:\n",
      "[256]\ttrain-auc:0.99691\teval-auc:0.98857\n",
      "\n",
      "[0.9917938387500198, 0.9885687539005616]\n",
      "************************************ 3 ************************************\n",
      "[21:45:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.97983\teval-auc:0.98573\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.99540\teval-auc:0.99427\n",
      "[400]\ttrain-auc:0.99706\teval-auc:0.99442\n",
      "Stopping. Best iteration:\n",
      "[399]\ttrain-auc:0.99705\teval-auc:0.99443\n",
      "\n",
      "[0.9917938387500198, 0.9885687539005616, 0.9944283402393698]\n",
      "************************************ 4 ************************************\n",
      "[21:46:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.98216\teval-auc:0.97621\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.99541\teval-auc:0.99296\n",
      "[400]\ttrain-auc:0.99705\teval-auc:0.99330\n",
      "[600]\ttrain-auc:0.99784\teval-auc:0.99345\n",
      "[800]\ttrain-auc:0.99830\teval-auc:0.99357\n",
      "[1000]\ttrain-auc:0.99855\teval-auc:0.99355\n",
      "Stopping. Best iteration:\n",
      "[957]\ttrain-auc:0.99851\teval-auc:0.99363\n",
      "\n",
      "[0.9917938387500198, 0.9885687539005616, 0.9944283402393698, 0.993631446564669]\n",
      "************************************ 5 ************************************\n",
      "[21:46:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.98196\teval-auc:0.98615\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "[200]\ttrain-auc:0.99516\teval-auc:0.99435\n",
      "[400]\ttrain-auc:0.99687\teval-auc:0.99458\n",
      "Stopping. Best iteration:\n",
      "[338]\ttrain-auc:0.99649\teval-auc:0.99462\n",
      "\n",
      "[0.9917938387500198, 0.9885687539005616, 0.9944283402393698, 0.993631446564669, 0.9946158528020975]\n",
      "xgb_scotrainre_list: [0.9917938387500198, 0.9885687539005616, 0.9944283402393698, 0.993631446564669, 0.9946158528020975]\n",
      "xgb_score_mean: 0.9926076464513436\n",
      "xgb_score_std: 0.00225259500578805\n"
     ]
    }
   ],
   "source": [
    "xgb_test = xgb_model(train, label, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.997156\tvalid_1's auc: 0.991331\n",
      "[400]\ttraining's auc: 0.998769\tvalid_1's auc: 0.991546\n",
      "[600]\ttraining's auc: 0.999288\tvalid_1's auc: 0.991548\n",
      "[800]\ttraining's auc: 0.999543\tvalid_1's auc: 0.991606\n",
      "Early stopping, best iteration is:\n",
      "[671]\ttraining's auc: 0.999388\tvalid_1's auc: 0.99177\n",
      "[0.9917700929253274]\n",
      "************************************ 2 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.997528\tvalid_1's auc: 0.987523\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's auc: 0.996014\tvalid_1's auc: 0.988037\n",
      "[0.9917700929253274, 0.9880373319212512]\n",
      "************************************ 3 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.996733\tvalid_1's auc: 0.994\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's auc: 0.995553\tvalid_1's auc: 0.994154\n",
      "[0.9917700929253274, 0.9880373319212512, 0.9941544699542957]\n",
      "************************************ 4 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.996748\tvalid_1's auc: 0.993104\n",
      "[400]\ttraining's auc: 0.998388\tvalid_1's auc: 0.99338\n",
      "[600]\ttraining's auc: 0.999055\tvalid_1's auc: 0.993482\n",
      "Early stopping, best iteration is:\n",
      "[587]\ttraining's auc: 0.999025\tvalid_1's auc: 0.993533\n",
      "[0.9917700929253274, 0.9880373319212512, 0.9941544699542957, 0.9935331051307752]\n",
      "************************************ 5 ************************************\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.996801\tvalid_1's auc: 0.994213\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's auc: 0.995334\tvalid_1's auc: 0.994324\n",
      "[0.9917700929253274, 0.9880373319212512, 0.9941544699542957, 0.9935331051307752, 0.9943240721542609]\n",
      "lgb_scotrainre_list: [0.9917700929253274, 0.9880373319212512, 0.9941544699542957, 0.9935331051307752, 0.9943240721542609]\n",
      "lgb_score_mean: 0.9923638144171821\n",
      "lgb_score_std: 0.0023446643435150573\n"
     ]
    }
   ],
   "source": [
    "lgb_test = lgb_model(train, label, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923.5839730163598\n",
      "929.6832208554812\n"
     ]
    }
   ],
   "source": [
    "print(xgb_test.sum())\n",
    "print(lgb_test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_test = lgb_test * 0.5 + xgb_test * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['score'] = rh_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82750f1b9d1223508ee329d47e27d35176c93eb9f35e9c1a</td>\n",
       "      <td>0.019012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f000950527a6feb670cc1c87c2025f3922aaa4a0206a0a33</td>\n",
       "      <td>0.702373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e9f7b28ec10e04700ef4db75a494f9a1e8e8b09555e6afa1</td>\n",
       "      <td>0.001019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beb4aaaa89e0a0ae9d77bd5d7665be6342f552f51840cf19</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e9f7b28ec10e0470ee4172cec0133b6826c34f27d3dff204</td>\n",
       "      <td>0.001479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>f000950527a6feb6b9e9c5a82689e87ee128abcf72ca7b96</td>\n",
       "      <td>0.108808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>d8071a739aa75a3bb98b032a18ae492bb8cf7ad9e0c23acd</td>\n",
       "      <td>0.064366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>f000950527a6feb63ae3783e4b82cbd8da7b3eaf43624866</td>\n",
       "      <td>0.001795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>d8071a739aa75a3bf8557cd0432d5c04e2241aee9f422220</td>\n",
       "      <td>0.001072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>f000950527a6feb6018eda95d4e4ae8cbdd85c30d3cd342a</td>\n",
       "      <td>0.840332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id     score\n",
       "0     82750f1b9d1223508ee329d47e27d35176c93eb9f35e9c1a  0.019012\n",
       "1     f000950527a6feb670cc1c87c2025f3922aaa4a0206a0a33  0.702373\n",
       "2     e9f7b28ec10e04700ef4db75a494f9a1e8e8b09555e6afa1  0.001019\n",
       "3     beb4aaaa89e0a0ae9d77bd5d7665be6342f552f51840cf19  0.000536\n",
       "4     e9f7b28ec10e0470ee4172cec0133b6826c34f27d3dff204  0.001479\n",
       "...                                                ...       ...\n",
       "9995  f000950527a6feb6b9e9c5a82689e87ee128abcf72ca7b96  0.108808\n",
       "9996  d8071a739aa75a3bb98b032a18ae492bb8cf7ad9e0c23acd  0.064366\n",
       "9997  f000950527a6feb63ae3783e4b82cbd8da7b3eaf43624866  0.001795\n",
       "9998  d8071a739aa75a3bf8557cd0432d5c04e2241aee9f422220  0.001072\n",
       "9999  f000950527a6feb6018eda95d4e4ae8cbdd85c30d3cd342a  0.840332\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[['id','score']].to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
